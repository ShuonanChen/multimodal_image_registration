{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d78793b6",
   "metadata": {},
   "source": [
    "# napari gui for manual matchings\n",
    "to use this, we need to make sure the data files (tiff images) are organized in the way we want!  \n",
    "\n",
    "this notebook therefore does two things:\n",
    "\n",
    "1. load the data and arrange in the way we want -- this is necessary for us to load the channles correctly\n",
    "2. launch napari to do the manual registration and save the results.\n",
    "\n",
    "for how to load the results and then stitch the original images, that will be in the other notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369e21d9",
   "metadata": {},
   "source": [
    "# 0. setup the environment and define the functinos needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "862e0cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100323\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "import tifffile\n",
    "import napari\n",
    "import os \n",
    "import glob\n",
    "import pprint\n",
    "import numpy as np\n",
    "import pickle\n",
    "# import helpers\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(suppress=True)\n",
    "import scipy.ndimage as ndi\n",
    "from skimage.transform import warp\n",
    "from scipy.spatial import distance\n",
    "import math\n",
    "\n",
    "from datetime import date\n",
    "today = date.today()\n",
    "todaystamp = today.strftime(\"%m%d%y\")\n",
    "print(todaystamp)\n",
    "\n",
    "def wahba(X,Y):\n",
    "    '''\n",
    "    from X to Y transform\n",
    "    '''\n",
    "    X0=X-np.mean(X,axis=0)    \n",
    "    Y0=Y-np.mean(Y,axis=0)    \n",
    "    U, _, Vt = np.linalg.svd(X0.T@Y0)\n",
    "    V = Vt.T\n",
    "    M = np.eye(2)\n",
    "    M[-1,:] = np.array((0,np.linalg.det(U)*np.linalg.det(V)))\n",
    "    R = U@M@V.T\n",
    "    T = np.mean(Y-X@R, axis = 0)\n",
    "    return(np.r_[R,T[None,:]])  # return 4x3 matrix (to transform from first input to second inpupt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae7d694",
   "metadata": {},
   "source": [
    "# 1. set up the directory. \n",
    "`file_dir` example:\n",
    "```\n",
    "!ls -lt /Users/shuonan/Dropbox/project/multimodal_2023/xinxindata/G126_data/tifs/ \n",
    "\n",
    "total 0\n",
    "drwx------@ 6 shuonanchen  staff  192 Feb 18 19:00 MERFISH_DAPI\n",
    "drwx------@ 6 shuonanchen  staff  192 Feb 18 18:59 MERFISH_GCaMP\n",
    "drwx------@ 6 shuonanchen  staff  192 Feb 18 18:59 MERFISH_polyA\n",
    "drwx------@ 6 shuonanchen  staff  192 Feb 17 16:13 MERFISH_tdTomato_G126\n",
    "drwx------@ 7 shuonanchen  staff  224 Feb 17 16:13 MERFISH_BV_G126\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abeb43f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is where the results will be saved. \n",
    "base_dir = '/Users/shuonan/Dropbox/project/multimodal_2023/xinxindata/G126_data/napari_rez/'\n",
    "\n",
    "# this is where the files are located. \n",
    "file_dir = '/Users/shuonan/Dropbox/project/multimodal_2023/xinxindata/G126_data/tifs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd26c90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tdTomato', 'BV', 'DAPI', 'GCaMP', 'polyA']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_files = glob.glob(file_dir+'/*')\n",
    "channel_name = [f.split('/')[-1].split('_')[1] for f in all_files]\n",
    "print(channel_name)  # these are all the available channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4454b7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify how many (or which) channels you want to load. \n",
    "C = len(channel_name) # if loading all the channels. \n",
    "C = 2  # by default lets only look at the tomato and BV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35673f21",
   "metadata": {},
   "source": [
    "# 2. load and arrange the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "778392ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "exvivos = []\n",
    "exvivos.append(np.nan)  # this is to make it consistent -- exvivos[0] is nothing, since the section_id starts from 1.\n",
    "for section_id in range(1,5):  # only looking at section 1,2,3,4. \n",
    "    all_channels_img = []\n",
    "    for f in all_files[:C]:\n",
    "        f_path = glob.glob(f+f'/*section{section_id}.tif*')\n",
    "        assert(len(f_path)==1)\n",
    "        f_path = f_path[0]\n",
    "        img = tifffile.imread(f_path)\n",
    "        img = img.astype(float)\n",
    "        img /= img.max()\n",
    "        all_channels_img.append(img)\n",
    "    exvivos.append(np.stack(all_channels_img, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcf3a9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exvivos)  # this should be 5 == 4+1 (1 is the nan part, 4 is the number of sections we are looking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d6ca4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 8, 2241, 2740),\n",
       " (2, 8, 2241, 2741),\n",
       " (2, 8, 2645, 2943),\n",
       " (2, 8, 2645, 2943)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the size of each\n",
    "[m.shape for m in exvivos[1:]]  # these are (c,z,x,y) where c is the number of channel (2), z should be 8 always. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8741f0",
   "metadata": {},
   "source": [
    "**okay the data is ready, now we are ready to launch the GUI.**\n",
    "# 3. launch GUI\n",
    "- notes\n",
    "    - only look a pair at a time\n",
    "    - dont forget to save (`q`)\n",
    "- how to use\n",
    "    1. select `section_id`: if `section_id=1`, then section 1 (red) and 2 (green) will be loaded. the larger index is always the source, mapped to the smaller one. (2 is transformed to map 1).\n",
    "    2. focus on BV layer, adjust the gamma and contrast. hide the ohter channels when necessary.\n",
    "    3. go to the `matched` layer, add points in both green and red. Note the number of points in green and red must be the same. \n",
    "    4. do the necessary transformation until you are bored with these layer (BV), then swtich to the tomato layer (hide BV, show tomato)\n",
    "    5. you can clean the selected, or add more spots based on the tomato layer. \n",
    "    6. check the console output (from this notebook) for the necessary informations. \n",
    "    7. the saved results would contain (1) all the transformations applied; and (2) transformed image. \n",
    "- keys (in the using order)\n",
    "    - `s`: scaling --> learn the scale and adjust the images \n",
    "    - `t`: transform --> rigid transformation\n",
    "    - `c`: clear --> clear all selection of matched points. \n",
    "    - `d`: deformable --> apply deformable for the matched points.\n",
    "    - `q`: quit --> well it doesnt quit the gui, it just save the results so dont press this unless you are done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b044a699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose your section_id\n",
    "section_id = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53d3ee40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying rigid..\n",
      "learning scale..\n",
      "scale difference: 0.9982306505448446\n",
      "applying rigid..\n",
      "learning scale..\n",
      "scale difference: 1.0020945622556776\n",
      "applying rigid..\n",
      "applying rigid..\n",
      "applying deformable..\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features = {'label': np.empty(0, dtype=int)}\n",
    "all_transform = []\n",
    "viewer = napari.view_image(exvivos[section_id][:,0],channel_axis=0,\n",
    "        name=[f'sec {section_id}...{c}' for c in channel_name],\n",
    "        colormap='red', visible = [True,True,False,False,False],)\n",
    "exvivo_layer = viewer.add_image(exvivos[section_id+1][:,-1],channel_axis=0,\n",
    "        name=[f'sec {section_id+1}...{c}' for c in channel_name],\n",
    "        colormap=\"green\", visible = [True,True,False,False,False],)\n",
    "pl_in = viewer.add_points(\n",
    "    size=5, edge_width=1, edge_color='red',face_color='transparent',    \n",
    "    name=f\"matched section {section_id}\", text='label', features=features,ndim=2,out_of_slice_display=True)\n",
    "@pl_in.events.data.connect\n",
    "def update_feature_default_invivo():  \n",
    "    global points_layer\n",
    "    no_of_points = len(pl_in.data)\n",
    "    pl_in.feature_defaults['label'] = no_of_points + 1\n",
    "    pl_in.properties[\"label\"][0:no_of_points] = range(1, no_of_points+1)\n",
    "    pl_in.text.values[0:no_of_points] = [str(i) for i in range(1, no_of_points+1)]\n",
    "    pl_in.text.color = 'red'\n",
    "    pl_in.text.translation = np.array([-10, 0])\n",
    "update_feature_default_invivo()\n",
    "pl_in.mode = 'add'\n",
    "\n",
    "pl_ex = viewer.add_points(\n",
    "    size=5, edge_width=1, edge_color='green',face_color='transparent',    \n",
    "    name=f\"matched section {section_id+1}\", text='label', features=features,ndim=2,out_of_slice_display=True)\n",
    "@pl_ex.events.data.connect\n",
    "def update_feature_default_exvivo():  \n",
    "    global points_layer\n",
    "    no_of_points = len(pl_ex.data)\n",
    "    pl_ex.feature_defaults['label'] = no_of_points + 1\n",
    "    pl_ex.properties[\"label\"][0:no_of_points] = range(1, no_of_points+1)\n",
    "    pl_ex.text.values[0:no_of_points] = [str(i) for i in range(1, no_of_points+1)]\n",
    "    pl_ex.text.color = 'green'\n",
    "    pl_ex.text.translation = np.array([-10, 0])\n",
    "update_feature_default_exvivo()\n",
    "pl_ex.mode = 'add'\n",
    "\n",
    "@viewer.bind_key('s', overwrite = True)\n",
    "def scale(viewer):  \n",
    "    print('learning scale..')\n",
    "    m_invivo = viewer.layers[f\"matched section {section_id}\"].data\n",
    "    m_exvivo = viewer.layers[f\"matched section {section_id+1}\"].data \n",
    "    assert(len(m_invivo)==len(m_exvivo))    \n",
    "    s_invivo = np.sqrt(np.sum((m_invivo-np.mean(m_invivo,0))**2)/len(m_invivo))\n",
    "    s_exvivo = np.sqrt(np.sum((m_exvivo-np.mean(m_exvivo,0))**2)/len(m_exvivo))\n",
    "    scl = s_invivo/s_exvivo\n",
    "    print(f'scale difference: {scl}')\n",
    "    m_exvivo_new = scl*m_exvivo    \n",
    "    exvivo_scaled_small = np.array([ndi.zoom(exvivo_layer[c].data, scl, order=3) for c in range(C)])    \n",
    "    all_transform.append(dict(scale=scl))\n",
    "    for c in range(C):\n",
    "        exvivo_layer[c].data = exvivo_scaled_small[c]\n",
    "    viewer.layers[f\"matched section {section_id+1}\"].data = m_exvivo_new    \n",
    "    \n",
    "\n",
    "@viewer.bind_key('t', overwrite = True)\n",
    "def transform(viewer):    \n",
    "    print('applying rigid..')\n",
    "    m_invivo = viewer.layers[f\"matched section {section_id}\"].data\n",
    "    m_exvivo = viewer.layers[f\"matched section {section_id+1}\"].data\n",
    "    assert(len(m_invivo)==len(m_exvivo))\n",
    "    bhat = wahba(m_exvivo,m_invivo)\n",
    "    offset = -(bhat[:2,:2])@bhat[-1]\n",
    "    exvivo_affined = np.array([ndi.affine_transform(exvivo_layer[c].data, bhat[:2,:2],\n",
    "                                                    output_shape = exvivo_layer[0].data.shape,offset = offset, order=3) for c in range(C)])\n",
    "    foo = np.c_[m_exvivo, np.ones((m_exvivo.shape[0],1))]   #Nx4\n",
    "    m_exvivo_update = foo@bhat\n",
    "    all_transform.append(dict(bhat=bhat))\n",
    "    for c in range(C):\n",
    "        exvivo_layer[c].data = exvivo_affined[c]\n",
    "    viewer.layers[f\"matched section {section_id+1}\"].data = m_exvivo_update\n",
    "\n",
    "    \n",
    "@viewer.bind_key('d', overwrite = True)\n",
    "def deform(viewer):    \n",
    "    print('applying deformable..')\n",
    "    ksz = 200\n",
    "    m_invivo = viewer.layers[f\"matched section {section_id}\"].data\n",
    "    m_exvivo = viewer.layers[f\"matched section {section_id+1}\"].data\n",
    "    assert(len(m_invivo)==len(m_exvivo))    \n",
    "    shift = m_invivo-m_exvivo   # so the newcoords = old+shift --> vecfield will have how much shift needed to apply to the old coords\n",
    "    vec_field = np.zeros(exvivo_layer[0].data.shape + (2,))  # M1,M2,2\n",
    "    for p,loc in enumerate(m_exvivo):\n",
    "        vec_field[int(loc[0]),int(loc[1])] = shift[p]\n",
    "    for c in range(2):\n",
    "        vec_field[...,c] = ndi.gaussian_filter(vec_field[...,c], ksz)\n",
    "    A = np.zeros_like(m_exvivo)\n",
    "    for p,loc in enumerate(m_exvivo):\n",
    "        A[p] = vec_field[int(loc[0]),int(loc[1])]\n",
    "    diag_step,_,_,_ = np.linalg.lstsq(A,shift,rcond=None)\n",
    "    step = np.diag(diag_step)\n",
    "    vec_field_total =vec_field*step;  # element wise. \n",
    "    all_transform.append(dict(vec_field_total=vec_field_total))\n",
    "    mapx_base, mapy_base = np.meshgrid(np.arange(exvivo_layer[0].data.shape[0]),np.arange(exvivo_layer[0].data.shape[1]), indexing='ij')\n",
    "    mapx=mapx_base-vec_field_total[:,:,0]\n",
    "    mapy=mapy_base-vec_field_total[:,:,1]\n",
    "    for c in range(C):\n",
    "        img_de = warp(exvivo_layer[c].data,np.array((mapx,mapy)), order = 3)            \n",
    "        exvivo_layer[c].data = img_de    \n",
    "    \n",
    "    m_exvivo_new = np.zeros_like(m_exvivo)  # POINTS\n",
    "    for p,loc in enumerate(m_exvivo):\n",
    "        new_s = vec_field_total[int(loc[0]),int(loc[1])]\n",
    "        m_exvivo_new[p] = loc+new_s\n",
    "    viewer.layers[f\"matched section {section_id+1}\"].data = m_exvivo_new\n",
    "    \n",
    "@viewer.bind_key('c')\n",
    "def clear_selected(viewer):        \n",
    "    viewer.layers[f\"matched section {section_id}\"].data = np.empty((0, 2))\n",
    "    viewer.layers[f\"matched section {section_id+1}\"].data = np.empty((0, 2))\n",
    "\n",
    "    \n",
    "@viewer.bind_key('q')\n",
    "def save_rez(viewer):     \n",
    "    out_dict = dict()\n",
    "    out = np.array([exvivo_layer[c].data for c in range(2)] )\n",
    "    out_dict[f'transformed_section_{section_id+1}']=out\n",
    "    out_dict['transformations']=all_transform    \n",
    "    pickle.dump(out_dict, open(base_dir + f'section_{section_id}_{section_id+1}_{todaystamp}.pkl','wb'))\n",
    "    print(\"saved the results!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "457bb0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'022123'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todaystamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada147eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa38b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762b1034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv2",
   "language": "python",
   "name": "cv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
