{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee74b074",
   "metadata": {},
   "source": [
    "# stitch the sections based on the tranformation learned on napari\n",
    "- this notebook accounts for the OOM problems "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0acf4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import glob, sys, os\n",
    "import tifffile\n",
    "import scipy.ndimage as ndi\n",
    "from skimage.transform import warp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def pad_2d(a,out_shape):\n",
    "    assert(len(a.shape)==2)\n",
    "    assert(len(a.shape)==len(out_shape))\n",
    "    if np.product((np.array(out_shape)-np.array(a.shape))>0)==0:\n",
    "        out = np.zeros(out_shape)\n",
    "        expand_axes = np.where((np.array(out_shape)-np.array(a.shape))>0)[0]\n",
    "        if expand_axes==0:            \n",
    "            out[:a.shape[0],:] = a[:,out_shape[1]]\n",
    "        if expand_axes==1:            \n",
    "            out[:, :a.shape[1]] = a[out_shape[0],:]\n",
    "    else:\n",
    "        out = np.zeros(out_shape)\n",
    "        out[:a.shape[0], :a.shape[1]] = a\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00a3c5c",
   "metadata": {},
   "source": [
    "# set the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c1a2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is where the files are located. \n",
    "file_dir = '/home/ubuntu/largevolume2/massimo_xinxin/data/G128/exvivo/' \n",
    "\n",
    "# this is where the results pkl files were saved from napari. \n",
    "base_dir = '/home/ubuntu/largevolume2/massimo_xinxin/napari_rez/G128/MERFISH_transformation/'\n",
    "\n",
    "\n",
    "# this is where the results will be saved. \n",
    "base_dir = '/pathtodownloadfile/napari_rez/'\n",
    "\n",
    "# this is where the files are located. \n",
    "file_dir = '/pathtodownloadfile/tifs/'\n",
    "\n",
    "\n",
    "# this is where the output will be saved (default is the same as base_dir). \n",
    "out_dir = '/pathtodownloadfile/napari_rez/'\n",
    "\n",
    "isExist = os.path.exists(out_dir)\n",
    "if not isExist:\n",
    "    os.makedirs(out_dir)\n",
    "    print(\"The new directory is created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd9cdf3",
   "metadata": {},
   "source": [
    "# set the number of sections "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0377ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_range=[1,2,3]\n",
    "section_range=list(np.arange(1,13))\n",
    "\n",
    "all_files = glob.glob(file_dir+'/*')\n",
    "channel_name = [f.split('/')[-1].split('_')[1] for f in all_files]\n",
    "print(channel_name)\n",
    "C = len(channel_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1194cf53",
   "metadata": {},
   "source": [
    "# set the output shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce48596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to get the biggest shape i guess\n",
    "f=all_files[0]\n",
    "shape_list = []\n",
    "for f_path in glob.glob(f+f'/*section*.tif*'):        \n",
    "    shape_list.append(np.array((tifffile.imread(f_path)).shape))\n",
    "out_shape = np.max(np.array(shape_list),0)\n",
    "print(out_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce15d1d8",
   "metadata": {},
   "source": [
    "# load all the transformation (from napari results)Â¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36e2117",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = dict()\n",
    "for section_id in section_range[:-1]:\n",
    "    rez_dir = base_dir + f'/section_{section_id}_{section_id+1}_021923.pkl'\n",
    "    rez = pickle.load(open(rez_dir, 'rb'))\n",
    "    T[section_id+1] = rez['transformations']\n",
    "for v in T.values():\n",
    "    assert(list(v[-1].keys())[0]=='vec_field_total')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb6c42c",
   "metadata": {},
   "source": [
    "## function that applies `T`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6db4ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans(source,T_dict,o_shape):  # original when source image is of size (c,z,x,y)\n",
    "    '''o_shape = (source.shape[1],) + exvivos[section_id][0].shape[1:] -- # (z,x,y)'''\n",
    "    assert(len(source.shape)==4)  # this is (c,z,x,y) where c==2 for now. z can be 8,16,24....\n",
    "    all_vec_f_3 = np.zeros(tuple(o_shape) + (3,))\n",
    "    B = np.eye(3)\n",
    "    for l in T_dict:\n",
    "        for k,v in l.items():\n",
    "            if k=='bhat':\n",
    "                B = B@((np.c_[v, np.array((0,0,1))]))\n",
    "            if k=='scale':\n",
    "                B[:,:2] *= v  \n",
    "            if k=='vec_field_total':\n",
    "                vf = np.stack([pad_2d(v[...,c],out_shape = o_shape[1:]) for c in range(2)], -1)\n",
    "                vf_3 = np.concatenate((np.zeros(vf.shape[:-1])[...,None], vf), 2)\n",
    "                all_vec_f_3 += vf_3\n",
    "    R_3 = np.eye(3); R_3[1:,1:] = (np.linalg.inv(B[:2,:2])).T\n",
    "    offset_3 = np.zeros(3); offset_3[1:] = -B[-1,:-1]@np.linalg.inv(B[:2,:2])\n",
    "    print('running rigid..')\n",
    "    transformed_all = np.array([ndi.affine_transform(source[c].astype('float32'), R_3, offset = offset_3,\n",
    "                                    output_shape = o_shape, order=3) for c in range(2)])\n",
    "    \n",
    "    mapz_base, mapx_base, mapy_base = np.meshgrid(np.arange(o_shape[0]),np.arange(o_shape[1]), np.arange(o_shape[2]),indexing='ij')\n",
    "    mapz=mapz_base-all_vec_f_3[:,:,:,0]\n",
    "    mapx=mapx_base-all_vec_f_3[:,:,:,1]\n",
    "    mapy=mapy_base-all_vec_f_3[:,:,:,2]\n",
    "    print('running deformable..')\n",
    "    deformed_all = np.array([warp(transformed_all[c],np.array((mapz,mapx,mapy)), order = 3) for c in range(2)])\n",
    "    return(deformed_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b34664",
   "metadata": {},
   "source": [
    "# now apply the transformation to all the sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8777c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for section_id in np.arange(2,section_range[-1]+1):  #[4,3,2]\n",
    "    print(f'...running for sec{section_id}...')\n",
    "    all_channels_img = []\n",
    "    for c in range(C):\n",
    "        f = all_files[c]\n",
    "        f_path = glob.glob(f+f'/*section{section_id}.tif*')\n",
    "        assert(len(f_path)==1)\n",
    "        img = tifffile.imread(f_path[0])        \n",
    "        img = img.astype(float)\n",
    "        img /= img.max()\n",
    "        all_channels_img.append(img)\n",
    "    source = np.stack(all_channels_img, axis = 0)\n",
    "    print(source.shape)\n",
    "    foo_p = source.copy()\n",
    "    for sec_id_p in np.arange(2,section_id+1)[::-1]:\n",
    "        print(f'...applying T({sec_id_p})...')\n",
    "        foo = foo_p.copy()\n",
    "        foo_p = trans(foo, T[sec_id_p], out_shape)\n",
    "        plt.figure(figsize =(20,10))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(foo[0][4])\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(foo_p[0][4])\n",
    "    out = foo_p\n",
    "    print(out.shape)\n",
    "    pickle.dump(out, open(f'/home/ubuntu/largevolume2/massimo_xinxin/pkl/G126_exvivos/tranformed_sec{section_id}.pkl','wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8185055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43cc567a",
   "metadata": {},
   "source": [
    "# load all transformed resutls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec14e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = dict()\n",
    "for section_id in section_range:\n",
    "    print(section_id)\n",
    "    if section_id == 1:\n",
    "        all_channels_img = []\n",
    "        for c in range(C):\n",
    "            f = all_files[c]\n",
    "            f_path = glob.glob(f+f'/*section{section_id}.tif*')\n",
    "            assert(len(f_path)==1)\n",
    "            img = tifffile.imread(f_path[0])        \n",
    "            img = img.astype(float)\n",
    "            img /= img.max()\n",
    "            img_foo = img.copy()\n",
    "            for z in range(z.shape[0]):\n",
    "                img[z]=pad_2d(img_foo[z],out_shape = out_shape[1:])\n",
    "            all_channels_img.append(img)\n",
    "        data_dict[f'sec{section_id}'] =  np.stack(all_channels_img, axis = 0)        \n",
    "        print(data_dict[f'sec{section_id}'].shape)\n",
    "    else:\n",
    "        f_path = out_dir + f'/tranformed_sec{section_id}.pkl'\n",
    "        data_dict[f'sec{section_id}'] = pickle.load(open(f_path,'rb'))\n",
    "        print(data_dict[f'sec{section_id}'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666b73d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be67dd82",
   "metadata": {},
   "source": [
    "### check teh results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13b8da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "plt.figure(figsize = (20,20))\n",
    "for i in range(1,5):\n",
    "    img = data_dict[f'sec{i}'][c][4].astype(float)\n",
    "    plt.subplot(2,2,i)\n",
    "    plt.imshow(img, vmin = np.quantile(img, 0.5), vmax = np.quantile(img, 0.9999))\n",
    "    plt.title(f'sec{i}')\n",
    "plt.tight_layout()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c202f2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50022d2a",
   "metadata": {},
   "source": [
    "### stitch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f12afb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_out_p = data_dict['sec1']\n",
    "for section_id in section_range[1:]:    \n",
    "    new_snow = data_dict[f'sec{section_id}'] #\n",
    "    vol_out_p = np.concatenate((new_snow,vol_out_p),axis = 1)#[:,::-1]\n",
    "print(vol_out_p.shape)  # the order is sec4:1-8, sec3:1-8,sec2:1-8,sec1:1-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0683e8f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7912eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db280d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
